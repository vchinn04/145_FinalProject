# IJCAI 2021 - WhoIsWho Task1-kingsundad 具体试错和解题思路

[toc]

## 1. 整体思路

我们的整体思路分别特征构建，训练打分模型，解决NIL问题三大模块。

首先对同名消歧任务进行不同类型的特征构建，分别是：手工特征，基于 OAG-BERT与K-NRM的论文相关性匹配特征，以及基于论文网络嵌入的相似度特征。

接着利用不同类型的特征训练打分模型来输出每篇待分配论文归属于某个候选者的概率，打分模型包括Xgboost，LightGBM，CatBoost三类常见的模型以及基于MLP的神经网络模型。

对于NIL问题的处理，我们使用了三种解决方案。第一种解决方案是针对训练集做处理：在训练集中按照事先设定的比例来生成负例（即待分配论文不属于任何一个候选作者）。第二种是通过指定不同的阈值，去除模型输出低于阈值的实例。第三种解决方案是针对模型做处理：除了训练打分模型之外，还额外训练一个分类器用来额外捕捉打分模型输出分数的分布的特征。经过实验第三种解决方案最为有效。

## 2. 数据预处理

在这一部分介绍我们数据预处理的过程

### 2.1 数据集划分

我们将大赛提供的 `Training set` （训练数据）划分为产生多折的训练集和验证集。读取训练数据中的 `train_author.json`，得到其中所有的人名。再将训练数据中的人名较为均衡的划分成 **5** 份。利用其中的 **4** 份作为训练集，剩余的 **1** 份作为验证集。

对于每位作者，我们将其发表的所有论文按照论文发表时间排序，将最新的 20% 的论文作为待分配的论文（unassigned），剩余 80% 的论文作为作者档案（profile）中的论文。

### 2.2 构建索引

为方便之后为每篇待分配论文找出其候选作者列表，我们构造 name-aid-pids 字典形式的中间文件。name-aid-pids 的键为人名，值为 aid-pids 的字典。aid-pids 的键为作者ID，值为作者发表论文的列表，列表的每个元素为论文ID+'-'+作者序号。

同时，我们观察到线上测试集中部分待分配的作者名仅出现在 `Training set` 中，因此我们将基于 `Existing user files in the system` （系统中的作者档案）中的 `whole_author_profiles.json` 产生的 name-aid-pids 字典与基于 `Training set` 产生的字典合并，作为产生线上测试集候选作者的依据。

## 3. 特征构建

这部分介绍我们尝试使用的三类特征。

### 3.1 基于特征工程构造的特征

手工特征有两大类，第一类是关于共同作者的特征，第二类是对机构、会议、标题、关键词四部分都分别在8个维度对其构建的特征。

#### 3.1.1 关于共同作者的特征

| 特征名字                    | 解释                                                         |
| --------------------------- | ------------------------------------------------------------ |
| coauthor_tfidf              | 每个出现的coautho名字的 tfidf 值之和                         |
| paper_coauthor_tfidf_ratio  | coauthor_tfidf 除以本论文所有coautho名字 tfidf 值之和        |
| counted_coauthor_tfidf      | 每个coautho名字的 tfidf 值乘以其曾与候选者发表论文的数目     |
| author_coauthor_tfidf_ratio | counted_coauthor_tfidf 除以 所有曾于候选者共同发表论文的作者的名字的tfidf值乘以其共同发表的论文数 |

#### 3.1.2 关于机构、会议、标题、关键词的特征

以下是对机构、会议、标题、关键词四部分分别在8个维度对其构建的特征：

word集合：比如对于“机构”构建8维特征的话，word集合指的是用机构的字符串切分出来词的集合。

card距离值：当前待分配论文和候选作者档案中每篇论文都可以构建一个word集合，card距离=两集合交集大小除以两集合并集大小。

重复单词：比如对于“机构”构建8维特征的话，当前待分配论文和候选作者档案中每篇论文都可以构建一个word集合，重复单词就是两个word集合的交集。

| 特征名字          | 解释                                                   |
| ----------------- | ------------------------------------------------------ |
| max_jaro_score    | 当前待分配论文，与作者档案中每篇论文的jaro距离的最大值 |
| mean_jaro_score   | 当前待分配论文，与作者档案中每篇论文的jaro距离的平均值 |
| max_card_score    | 最大的card距离值                                       |
| mean_card_score   | 平均的card距离                                         |
| score_paper       | 重复单词在待分配论文中的个数乘以其tfidf值之和          |
| word_paper_ratio  | score_paper 除以待分配论文中所有单词的tfidf值之和      |
| score_author      | 重复单词在候选作者的论文中的个数乘以其tfidf值之和      |
| word_author_ratio | score_author除以作者发表的论文中所有word的tfidf值之和  |

### 3.2 基于 OAG-BERT和K-NRM的论文相关性匹配特征

这部分我们构建**待分配论文**与候选作者最近发过的**论文集合**的**相关性特征**。具体步骤如下：

第一步，利用OAG-BERT计算待分配论文、候选作者最近发过的论文集合（最多取40篇）的表征，分别记为$r_{unass} \in R^{1 \times d}$，$r_{candi} = \{r_{candi}^{1},r_{candi}^{2},r_{candi}^{i},...,r_{candi}^{l}\}\in R^{l \times d}$，$（0<l<=40）$，其中 $d=768$，即用768维的向量对每篇论文进行表示。

第二步，计算待分配论文与候选作者最近发过的论文集合的相似度矩阵$M = r_{unass}r_{candi}^{T}\in R^{1 \times d}$。由于$r_{unass}$和$r_{candi}$均为归一化之后的向量，因此$r_{unass}$和$r_{candi}^{i}$之间的内积，等同于余弦相似度，即 $M$ 中每个元素的值可以代表**待分配论文**与候选作者最近发过的论文集合中**每篇论文**的**语义相似度**。

第二步，对 $M$ 进行观察，我们发现了两个现象：

- **$M$中许多元素值都很小**，即候选作者的论文集合中很多论文和待分配论文的语义相似度不高。
- 候选作者最近发过的论文集合的**大小 $l$ 不固定**。

直接对 $M$ 进行截断或者填充成固定维度然后送入模型进行训练的话可能会导致丢失信息或者引入噪声，因此仅使用待分配论文与候选作者最近发过的论文的**语义相似度**特征不是一个好选择。为此，我们采用论文 *End-to-End Neural Ad-hoc Ranking with Kernel Pooling* 中提出的 K-NRM 来捕捉 $M$ 的分布的特征，且用固定维度来表示，进而得到**待分配论文**与候选作者最近发过的**论文集合**的**相关性特征**。不同于语义匹配，相关性匹配更关注以下两个要素：

- **精确的匹配信号`Exact matching signals`**：指的是对于论文集合中和待分配论文语义相似度较高的一些论文，计算这些论文在论文集合中出现的**频率特征**（Term Frequency, TF）。一般来说，具有某类特征的论文的重要性和其在论文集合中出现的频率成正比。通俗地说，如果具有某类特征的论文在一个论文集合中出现的频率很高，且具有该类特征的论文和待分配的论文又有很高的相似度，那么可以视为该论文集合和待分配的论文有很高的**相关性**。
- **多样化匹配`Diverse matching requirement`**：在候选作者发过的论文集合中，除了和待分配论文有很高语义相似度的论文之外，和待分配论文语义相似度不高的论文也能对待分配论文和论文集的相关性产生影响。

综上，我们利用径向基函数（Radial Basis Function, RBF）核来计算**不同语意相似度级别的论文对**（Paper Pair）的**频率 (Soft Term Frequency, SoftTF)**。 Term指的是Paper Pair，一个Paper Pair由论文集合中的一篇论文和待分配论文构成，一个Paper Pair的相似度就是 $M$ 中一个元素的值$M_{i}$。具体的实现如下公式：
$$
RBFK_{k}\left(\mathbf{M}_{i}\right) =\sum_{i=1}^{l} \exp \left[-\frac{\left(M_{i}-\mu_{k}\right)^{2}}{2 \sigma_{k}^{2}}\right]
$$

$$
RBFK\left(\mathbf{M}_{i}\right) =\left\{RBFK_{1}\left(\mathbf{M}_{i}\right), \cdots, RBFK_{K}\left(\mathbf{M}_{i}\right)\right\}
$$

$$
\phi(\mathbf M) =\sum_{i=1}^{l} \log RBFK\left(\mathbf{M}_{i}\right)，
$$

其中 $RBFK$ 表示径向基函数核，一共有 $K=41$ 个RBF核。$\mu$ 和 $\sigma$  d是RBF核函数的两个参数，通过调节𝜇，𝜎，可以控制精确匹配和语义匹配的程度，当𝜇=1,  𝜎→0时为精确匹配，当𝜇=0.5时为语义匹配，体现了SoftTF中"Soft"的意义。经过公式(1), (2), (3)步之后，我们用41维的向量 $\phi(\mathbf M)$去表示**待分配论文**与候选作者最近发过的**论文集合**的**相关性特征**。

### 3.3 基于论文网络嵌入的相似度特征

构造这一特征的总体思路为：首先按照论文的共同作者和共同机构等信息搭建论文异质网络，再利用网络嵌入的方法学习每个论文节点的表示向量，最后依据待分配论文（unassigned）与候选作者档案（profile）中多篇论文的表示向量构建相似矩阵，使用 RBF Kernel 进行 Kernel Pooling。

#### 3.3.1 论文关系表征学习

对于每一个需要消歧的名字，将与其相关的所有论文抽取出来，依据这些论文之间的共同作者及共同组织的相似性，构建一个以论文为节点、以论文间关系为边的网络。这里使用了两种类型的边：CoAuthor 和 CoOrg。

- CoAuthor 关系代表两篇论文之间存在共同作者（**排除待消歧的名字**），边的权值为拥有共同作者的个数。
- CoOrg 关系代表两篇论文**待消歧名字的机构**之间的相似性，边的权值为两个机构相同词的数量。

构建好上述的论文网络之后，使用基于元路径 (${p_1} \to {\text{CoAuthor}} \to {p_2} \to {\text{CoOrg}} \to {p_3}$) 的随机游走生成由论文 ID 组成的路径，再以这些路径作为 word2vec 模型训练的语料，以得到每个论文 ID 对应的表示向量。

#### 3.3.2 Kernel Pooling

通过上述过程，我们得到了每一篇待分配的论文和作者档案中论文的表示向量。这一步我们为每一个待分配论文及其对应候选者构建其特征。

有待分配论文的表征 $r_{unass} \in R^{d}$ 和 候选作者所有论文的表征 $r_{candi} \in R^{l \times d}$，其中 $d$ 为论文表示向量的维度，$l$ 为候选作者档案中论文个数。**通过计算余弦或欧式距离**，我们可以得到一个 $\mathbf{S}_i \in R^{l}$。


考虑到不同的候选作者的论文数量不尽相同，我们再这里使用 RBF核进行 Kernel Pooling，得到一个固定维度的特征，计算过程如下
$$
RBFK_{k}\left(\mathbf{S}_{i}\right) =\sum_{i=1}^{l} \exp \left[-\frac{\left(S_{i}-\mu_{k}\right)^{2}}{2 \sigma_{k}^{2}}\right]
$$

$$
RBFK\left(\mathbf{S}_{i}\right) =\left\{RBFK_{1}\left(\mathbf{S}_{i}\right), \cdots, RBFK_{K}\left(\mathbf{S}_{i}\right)\right\}
$$

$$
\phi(\mathbf S) =\sum_{i=1}^{l} \log RBFK\left(\mathbf{S}_{i}\right)，
$$

其中$RBFK_{k}$​ 为第 $k$​ 个RBF核，$K$​ 为RBF核的个数。经过公式(4), (5), (6)步之后，我们用41维的向量 $\phi(\mathbf S)$​​去表示**待分配论文**与候选作者最近发过的**论文集合**的**相似度特征**。


## 4. 训练模型

### 4.1 训练打分模型

在之前的过程中，我们构造了三类不同的特征——基于特征工程的特征（记为"**hand feature**"）、基于 OAG-BERT和K-NRM的论文相关性匹配特征（记为"**relevance feature**"）和基于论文网络嵌入的特征（记为"**graph feature**"）。可以构造出不同的特征组合

我们尝试使用过的分类器包括 XGBClassifier，CatBoostClassifier，LGBMClassifier，基于MLP的神经网络模型。在本次比赛中，对于单个模型来说，LGBMClassifier与（hand feature + relevance feature）的特征组合效果最好。

### 4.2 训练额外的分类器解决 NIL 问题

在本次比赛中有一个重要的问题的就是 NIL 问题，即待分配论文不属于候选作者集合中的任何一个作者。对于数据集中存在的 NIL 问题，我们尝试过三种方法来解决，第一种解决方案是针对训练集做处理：在训练集中按照事先设定的比例来生成负例（即待分配论文不属于任何一个候选作者）。第二种是通过指定不同的阈值，去除模型输出低于阈值的实例。第三种解决方案是针对模型做处理：除了训练打分模型之外，还额外训练一个分类器用来额外捕捉打分模型输出分数的分布的特征。经过实验第三种解决方案最为有效，这里介绍一下如何训练额外的分类器解决 NIL 问题。

#### 4.2.1 构造 NIL 的训练样例

在训练过程中，我们观察到正常方式构造的训练集合不存在 NIL 的样例，即对每一篇候选论文都存在其对应作者。为拟合测试集中的 NIL 样例，我们将 2.1 中构造的验证集取 $\alpha$ 的实例作为 NIL 样例，从其候选作者列表中删去其真实作者。实验中选取的 $\alpha$ 值为 0.2 。

#### 4.2.2 训练额外的分类器

对于每一篇待分配的论文，基础的分类器（如 XGBClassifier）为每个候选者给出一个打分。再基于基础分类器对每个候选者的打分，构造一个 4 维的整体分布特征（记为"**dis**"）。整体分布特征的定义如下：

- Top-1  作者得分；
- 所有候选作者的平均得分；
- (Top-1 作者得分-排名第二的作者得分) / (Top-1 作者得分-平均得分)；
- (Top-1 作者得分-排名第二的作者得分) / (Top-1 作者得分-排名最后作者得分)；

将这个整体分布特征与用于打分的特征组合进行结合，使用一个额外的分类器进行训练。

### 4.3 模型融合

经过实验，我们确定了最终的融合方案如下：

![whoiswho](具体试错和解题思路/whoiswho.png)

使用的单层打分模型包括 XGB、LGBM、Cat 三种类型，每种类型尝试两种不同的特征组合(hand feature) 和 (hand feature, relevance feature)，并进行5折交叉训练。

使用的双层模型（底层是打分模型，顶层模型用来解决NIL问题）一共有三类，每种类型尝试两种不同的特征组合(hand feature) 和 (hand feature, relevance feature)，不使用交叉验证训练。

最后对不同模型的输出取平均值，只保留阈值大于 0.65 的实例。


## 参考资料

[上届冠军分享：基于网络嵌入和语义表征的同名消歧](https://mp.weixin.qq.com/s/-di58Ikx9m1pEZp5JjXLQQ)

Chenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, and Russell Power. 2017. End-to-End Neural Ad-hoc Ranking with Kernel Pooling. Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval:55–64, August. arXiv: 1706.06613.
